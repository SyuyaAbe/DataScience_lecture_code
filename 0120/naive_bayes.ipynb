{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes による未知の文書の判定\n",
    "可視化を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 必要なライブラリの読み込み\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テキストの前処理で作成した処理後（単語分割後）のファイルを使い、どちらのカテゴリ(H1,H2)に、どの単語が、何回出現したかをカウントします。Pandasを利用することで、簡単に集計できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 教師データ：カテゴリ H1 H2 ごとの重複ありでの全部の単語が入る\n",
    "### 列名はデータにはなく（header=None）、\"W\"という名前の列名を付ける。\n",
    "raw_words = {}\n",
    "raw_words['H1'] = pd.read_table('mlit.txt',encoding='utf-8',header=None,names=('W'))\n",
    "raw_words['H2'] = pd.read_table('env.txt',encoding='utf-8',header=None,names=('W'))\n",
    "\n",
    "### カテゴリ H1 H2 ごと、各単語の出現回数\n",
    "word_count = {}\n",
    "word_count['H1'] = raw_words['H1']['W'].value_counts()\n",
    "word_count['H2'] = raw_words['H2']['W'].value_counts()   ### word_count['H1'].get('事業',0) 等で回数を使える\n",
    "\n",
    "### カテゴリ H1 H2 両方を通しての全部の出現単語（重複無し）\n",
    "all_words = pd.concat([raw_words['H1'],raw_words['H2']])['W'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理で作ったチェック用データに対して、ナイーブベイズフィルタによるカテゴリ判定を行います。<br>\n",
    "どちらになるかは五分五分（0.5）の事前確率からスタートし、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_words = {}\n",
    "check_words['Test1'] = pd.read_table('mlit_check.txt',encoding='utf-8',header=None,names=('W'))\n",
    "check_words['Test2'] = pd.read_table('env_check.txt',encoding='utf-8',header=None,names=('W'))\n",
    "\n",
    "posterior = { 'H1': math.log(0.5), 'H2': math.log(0.5) }\n",
    "for w in check_words['Test1']['W']:\n",
    "    for c in ['H1', 'H2']:\n",
    "        posterior[c] += math.log( float(word_count[c].get(w,0) + 1) / ( len(raw_words[c]) + 2 ) )\n",
    "\n",
    "print(\"H1 = \" + str(posterior['H1']) + \" ,H2 = \" + str(posterior['H2']) + \"\\n\")\n",
    "if posterior['H1'] > posterior['H2']:\n",
    "    print(\"Test1 is classified to H1\\n\" )\n",
    "else:\n",
    "    print(\"Test1 is classified to H2\\n\" )\n",
    "\n",
    "posterior = { 'H1': math.log(0.5), 'H2': math.log(0.5) }\n",
    "for w in check_words['Test2']['W']:\n",
    "    for c in ['H1', 'H2']:\n",
    "        posterior[c] += math.log( float(word_count[c].get(w,0) + 1) / ( len(raw_words[c]) + 2 ) )\n",
    "    \n",
    "print(\"H1 = \" + str(posterior['H1']) + \" ,H2 = \" + str(posterior['H2']) + \"\\n\")\n",
    "if posterior['H1'] > posterior['H2']:\n",
    "    print(\"Test2 is classified to H1\\n\" )\n",
    "else:\n",
    "    print(\"Test2 is classified to H2\\n\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
